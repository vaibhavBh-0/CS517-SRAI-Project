{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe9e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from evaluate import load\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "import accelerate\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605718c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "pipe = pipeline('text-generation', model=model_id, torch_dtype=torch.bfloat16)\n",
    "# LLama 3.2 has multiple eos_token_id. We use the \"128001\"\n",
    "pipe.tokenizer.pad_token_id = pipe.model.config.eos_token_id[0]\n",
    "\n",
    "_model = pipe.model\n",
    "_tokenizer = pipe.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f682e188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "quant8_config = BitsAndBytesConfig(load_in_8bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "quant8_model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quant8_config)\n",
    "quant8_pipe = pipeline('text-generation', model=quant8_model, tokenizer=_tokenizer, torch_dtype='auto')\n",
    "# LLama 3.2 has multiple eos_token_id. We use the \"128001\"\n",
    "quant8_pipe.tokenizer.pad_token_id = quant8_pipe.model.config.eos_token_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963aa520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "quant4_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_quant_type='nf4')\n",
    "quant4_model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quant4_config)\n",
    "quant4_pipe = pipeline('text-generation', model=quant4_model, tokenizer=_tokenizer, torch_dtype='auto')\n",
    "# LLama 3.2 has multiple eos_token_id. We use the \"128001\"\n",
    "quant4_pipe.tokenizer.pad_token_id = quant4_pipe.model.config.eos_token_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8219ee17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLama 3.2 1B Instruct with bfloat16 uses 2357.13MB of memory\n",
      "LLama 3.2 1B Instruct with bfloat16 and int8 uses 1429.13MB of memory\n",
      "LLama 3.2 1B Instruct with bfloat16 and int4 uses 965.13MB of memory\n"
     ]
    }
   ],
   "source": [
    "llama_1b = sum(param.numel() * param.element_size() for param in _model.parameters()) / (1024 ** 2)\n",
    "llama_1b_int8 = sum(param.numel() * param.element_size() for param in quant8_model.parameters()) /  (1024 ** 2)\n",
    "llama_1b_int4 = sum(param.numel() * param.element_size() for param in quant4_model.parameters()) /  (1024 ** 2)\n",
    "\n",
    "print(f'LLama 3.2 1B Instruct with bfloat16 uses {round(llama_1b, 2)}MB of memory')\n",
    "print(f'LLama 3.2 1B Instruct with bfloat16 and int8 uses {round(llama_1b_int8, 2)}MB of memory')\n",
    "print(f'LLama 3.2 1B Instruct with bfloat16 and int4 uses {round(llama_1b_int4, 2)}MB of memory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f334f",
   "metadata": {},
   "source": [
    "### CoQA Dataset without conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a9c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_for_coqa_question(context: str, question: str) -> list:\n",
    "    \"\"\"\n",
    "    Get prompt for CoQA in chat format. This includes a system and an user prompt.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {'role': 'system', 'content': f'You are a chatbot which answers user question in extremely concise manner possible from given context, \"{context}\".'},\n",
    "        {'role': 'user', 'content': question}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c376aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'story', 'questions', 'answers', 'question_prompt'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coqa_dataset = load_dataset('stanfordnlp/coqa', split='all')\n",
    "coqa_100 = coqa_dataset.select(range(50))\n",
    "coqa_100 = coqa_100.add_column('question_prompt', column=[get_prompt_for_coqa_question(context, questions[0]) \n",
    "                                                          for context, questions in zip(coqa_100['story'], coqa_100['questions'])])\n",
    "\n",
    "coqa_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d5d4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'You are a chatbot which answers user question in extremely concise manner possible from given context, \"The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is the library of the Holy See, located in Vatican City. Formally established in 1475, although it is much older, it is one of the oldest libraries in the world and contains one of the most significant collections of historical texts. It has 75,000 codices from throughout history, as well as 1.1 million printed books, which include some 8,500 incunabula. \\n\\nThe Vatican Library is a research library for history, law, philosophy, science and theology. The Vatican Library is open to anyone who can document their qualifications and research needs. Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail. \\n\\nIn March 2014, the Vatican Library began an initial four-year project of digitising its collection of manuscripts, to be made available online. \\n\\nThe Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items. \\n\\nScholars have traditionally divided the history of the library into five periods, Pre-Lateran, Lateran, Avignon, Pre-Vatican and Vatican. \\n\\nThe Pre-Lateran period, comprising the initial days of the library, dated from the earliest days of the Church. Only a handful of volumes survive from this period, though some are very significant.\".',\n",
       "  'role': 'system'},\n",
       " {'content': 'When was the Vat formally opened?', 'role': 'user'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coqa_100['question_prompt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f3cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bfloat16: 100%|██████████| 1000/1000 [00:55<00:00, 17.91it/s]\n",
      "int8: 100%|██████████| 1000/1000 [00:48<00:00, 20.70it/s]\n",
      "int4: 100%|██████████| 1000/1000 [01:04<00:00, 15.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Constrastive search sampling gives only one sample per input, so we sample it multiple times.\n",
    "# SAMPLING = 50\n",
    "SAMPLING = 20\n",
    "\n",
    "# Select as per the GPU?\n",
    "MULTIPLIER = 40\n",
    "\n",
    "# params for Constrastive Search Sampling.\n",
    "pipe_kwargs = {\n",
    "    'penalty_alpha': 0.6,\n",
    "    'top_k': 40, # 'top_k': 4,\n",
    "    'max_new_tokens': 128,\n",
    "    'pad_token_id': _tokenizer.pad_token_id,\n",
    "    'batch_size': 5 * MULTIPLIER\n",
    "}\n",
    "\n",
    "del MULTIPLIER\n",
    "\n",
    "# Originally, it's right side, but huggingface throws warning. \n",
    "# \"A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\"\n",
    "_tokenizer.padding_side = 'left'\n",
    "\n",
    "\n",
    "generations = {\n",
    "    'bfloat16': [],\n",
    "    'int8': [],\n",
    "    'int4': []\n",
    "}\n",
    "\n",
    "\n",
    "inference_ds = KeyDataset(coqa_100.repeat(SAMPLING), key='question_prompt')\n",
    "n = len(inference_ds)\n",
    "\n",
    "with tqdm(total=n, desc='bfloat16') as pbar:\n",
    "    for out in pipe(inference_ds, **pipe_kwargs):\n",
    "        generations['bfloat16'].append(out[0]['generated_text'])\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "with tqdm(total=n, desc='int8') as pbar:\n",
    "    for out in quant8_pipe(inference_ds, **pipe_kwargs):\n",
    "        generations['int8'].append(out[0]['generated_text'])\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "with tqdm(total=n, desc='int4') as pbar:\n",
    "    for out in quant4_pipe(inference_ds, **pipe_kwargs):\n",
    "        generations['int4'].append(out[0]['generated_text'])\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b48a7c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_for_verification(questions: str, answers: dict, chat_history: list, context: str) -> list:\n",
    "    \"\"\"\n",
    "    Get prompt in chat format. This includes a system and an user prompt.\n",
    "    \"\"\"\n",
    "    question = questions[0]\n",
    "    # print(answers.keys())\n",
    "    # answer = list(answers.values())[0]\n",
    "    answer = answers['input_text'][0]\n",
    "    response = chat_history[-1]['content']\n",
    "    \n",
    "    return [\n",
    "        {'role': 'system', 'content': 'For the following query is the response correct reply with True or False, nothing more. Look at the context or the answer'}, # , nothing more\n",
    "        {'role': 'user', 'content': f'From the context \"{context}\" the question \"{question}\", has the correct answer as \"{answer}\". Does the response \"{response}\" fits the correct answer?'}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5110fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'story', 'questions', 'answers', 'question_prompt', 'bfloat16_response', 'bfloat16_verification_prompt', 'int8_response', 'int8_verification_prompt', 'int4_response', 'int4_verification_prompt'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coqa_100_generations = coqa_100.repeat(SAMPLING)\n",
    "\n",
    "for key, value in generations.items():\n",
    "    name = f'{key}_response'\n",
    "    coqa_100_generations = coqa_100_generations.add_column(name, value)\n",
    "    coqa_100_generations = coqa_100_generations.add_column(f'{key}_verification_prompt', column=list(map(get_prompt_for_verification, \n",
    "                                                                                                       coqa_100_generations['questions'], \n",
    "                                                                                                       coqa_100_generations['answers'],\n",
    "                                                                                                       coqa_100_generations[name],\n",
    "                                                                                                       coqa_100_generations['story'])))\n",
    "\n",
    "coqa_100_generations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546d996",
   "metadata": {},
   "source": [
    "## Verify using Judge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e37d75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecb07637306455e8e556cea2e603de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "judge_model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "judge_pipe = pipeline('text-generation', model=judge_model_id, torch_dtype=torch.bfloat16)\n",
    "# LLama 3.2 has multiple eos_token_id. We use the \"128001\"\n",
    "judge_pipe.tokenizer.pad_token_id = judge_pipe.model.config.eos_token_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87d725ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bfloat16_verification: 100%|██████████| 25000/25000 [17:07<00:00, 24.33it/s]   \n",
      "int8_verification: 100%|██████████| 25000/25000 [17:07<00:00, 24.34it/s]   \n",
      "int4_verification: 100%|██████████| 25000/25000 [17:35<00:00, 23.68it/s]   \n"
     ]
    }
   ],
   "source": [
    "verification_pipe_kwargs = {\n",
    "    'pad_token_id': _tokenizer.pad_token_id,\n",
    "    'batch_size': 50\n",
    "}\n",
    "\n",
    "judge_pipe.tokenizer.padding_side = 'left'\n",
    "VERIFICATION_SAMPLES = 25\n",
    "\n",
    "verifications = {\n",
    "    'bfloat16': [],\n",
    "    'int8': [],\n",
    "    'int4': []\n",
    "}\n",
    "\n",
    "for key in verifications.keys():\n",
    "    verification_ds = KeyDataset(coqa_100_generations.repeat(VERIFICATION_SAMPLES), key=f'{key}_verification_prompt')\n",
    "    n = len(verification_ds)\n",
    "\n",
    "    with tqdm(total=n, desc=f'{key}_verification') as pbar:\n",
    "        for out in judge_pipe(verification_ds, **verification_pipe_kwargs):\n",
    "            verifications[key].append(out[0]['generated_text'])\n",
    "\n",
    "            pbar.update()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# out = judge_pipe([coqa_100_generations['bfloat16_verification_prompt'][3]] * 25, **verification_pipe_kwargs)\n",
    "# # out = judge_pipe(coqa_100_generations['bfloat16_verification_prompt'][0], **verification_pipe_kwargs)\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f649cb9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6aa6b8d27034529b74f5562faaad978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f5c93d2e0b4f8da647a0aca37dde3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coqa_100_verifications_25 = coqa_100_generations.repeat(VERIFICATION_SAMPLES)\n",
    "\n",
    "for key, value in verifications.items():\n",
    "    name = f'{key}_verification_response'\n",
    "    coqa_100_verifications_25 = coqa_100_verifications_25.add_column(name, value)\n",
    "\n",
    "coqa_100_generations.save_to_disk('coqa_100_slice')\n",
    "coqa_100_verifications_25.save_to_disk('coqa_100_verifications_25_slice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "112231a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25664 0.12516999379377652 0.25664 0.43677901781106654\n",
      "0.24988000000000007 0.12920936212419534 0.24988 0.43294339768611784\n",
      "0.24768 0.11947130476913087 0.24768 0.43166493672755024\n"
     ]
    }
   ],
   "source": [
    "for verification_key in ('bfloat16', 'int8', 'int4'): \n",
    "    verification_key = f'{verification_key}_verification_response'\n",
    "    arr = np.array([int('true' in chat[-1]['content'].lower()) for chat in coqa_100_verifications_25[verification_key]])\n",
    "    \n",
    "    # The first two dims are ordered following FIFO strategy to \n",
    "    # balance the 'tile' operations applied on the original 100 questions.\n",
    "    arr = arr.reshape(VERIFICATION_SAMPLES, SAMPLING, -1)\n",
    "    # We average the results over each verification for each sample.\n",
    "    mean_accuracy_per_sample : np.ndarray = arr.mean(axis=0)\n",
    "    # We then average and std over each sample for each question.\n",
    "    accuracy_per_question : np.ndarray = mean_accuracy_per_sample.mean(axis=0)\n",
    "    std_per_question : np.ndarray = mean_accuracy_per_sample.std(axis=0)\n",
    "\n",
    "    mean_accuracy = accuracy_per_question.mean(axis=0)\n",
    "    avg_std = std_per_question.mean(axis=0)\n",
    "\n",
    "    print(mean_accuracy, avg_std, arr.mean(), arr.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14d43c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Donner'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coqa_100_generations[3]['answers']['input_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30491ed7-b697-4a56-aefa-a16dc742a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "coqa_100_generations[3]['bfloat16_response']\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bfb9022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "correct_counts = np.array([int('true' in chat[0]['generated_text'][-1]['content'].lower()) for chat in out])\n",
    "print(correct_counts.mean())\n",
    "print(correct_counts.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8dc767d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'content': 'For the following query give response as True or False, nothing more.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'From the context \"The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is the library of the Holy See, located in Vatican City. Formally established in 1475, although it is much older, it is one of the oldest libraries in the world and contains one of the most significant collections of historical texts. It has 75,000 codices from throughout history, as well as 1.1 million printed books, which include some 8,500 incunabula. \\n\\nThe Vatican Library is a research library for history, law, philosophy, science and theology. The Vatican Library is open to anyone who can document their qualifications and research needs. Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail. \\n\\nIn March 2014, the Vatican Library began an initial four-year project of digitising its collection of manuscripts, to be made available online. \\n\\nThe Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items. \\n\\nScholars have traditionally divided the history of the library into five periods, Pre-Lateran, Lateran, Avignon, Pre-Vatican and Vatican. \\n\\nThe Pre-Lateran period, comprising the initial days of the library, dated from the earliest days of the Church. Only a handful of volumes survive from this period, though some are very significant.\" the question \"When was the Vat formally opened?\", has the correct answer as \"It was formally established in 1475\". Does the response \"The Vatican Library was formally established in 1475.\" fits the correct answer?',\n",
       "   'role': 'user'}],\n",
       " [{'content': 'For the following query give response as True or False, nothing more.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'From the context \"The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is the library of the Holy See, located in Vatican City. Formally established in 1475, although it is much older, it is one of the oldest libraries in the world and contains one of the most significant collections of historical texts. It has 75,000 codices from throughout history, as well as 1.1 million printed books, which include some 8,500 incunabula. \\n\\nThe Vatican Library is a research library for history, law, philosophy, science and theology. The Vatican Library is open to anyone who can document their qualifications and research needs. Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail. \\n\\nIn March 2014, the Vatican Library began an initial four-year project of digitising its collection of manuscripts, to be made available online. \\n\\nThe Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items. \\n\\nScholars have traditionally divided the history of the library into five periods, Pre-Lateran, Lateran, Avignon, Pre-Vatican and Vatican. \\n\\nThe Pre-Lateran period, comprising the initial days of the library, dated from the earliest days of the Church. Only a handful of volumes survive from this period, though some are very significant.\" the question \"When was the Vat formally opened?\", has the correct answer as \"It was formally established in 1475\". Does the response \"The Vatican Library was formally established in 1475.\" fits the correct answer?',\n",
       "   'role': 'user'}]]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[coqa_100_generations['bfloat16_verification_prompt'][0]] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bec9046b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'False'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0]['generated_text'][-1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c225a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': [{'content': 'For the following query give response as True or False, nothing more.',\n",
       "     'role': 'system'},\n",
       "    {'content': 'From the context \"The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is the library of the Holy See, located in Vatican City. Formally established in 1475, although it is much older, it is one of the oldest libraries in the world and contains one of the most significant collections of historical texts. It has 75,000 codices from throughout history, as well as 1.1 million printed books, which include some 8,500 incunabula. \\n\\nThe Vatican Library is a research library for history, law, philosophy, science and theology. The Vatican Library is open to anyone who can document their qualifications and research needs. Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail. \\n\\nIn March 2014, the Vatican Library began an initial four-year project of digitising its collection of manuscripts, to be made available online. \\n\\nThe Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items. \\n\\nScholars have traditionally divided the history of the library into five periods, Pre-Lateran, Lateran, Avignon, Pre-Vatican and Vatican. \\n\\nThe Pre-Lateran period, comprising the initial days of the library, dated from the earliest days of the Church. Only a handful of volumes survive from this period, though some are very significant.\" the question \"When was the Vat formally opened?\", has the correct answer as \"It was formally established in 1475\". Does the response \"The Vatican Library was formally established in 1475.\" fits the correct answer?',\n",
       "     'role': 'user'},\n",
       "    {'role': 'assistant', 'content': 'False'}]}],\n",
       " [{'generated_text': [{'content': 'For the following query give response as True or False, nothing more.',\n",
       "     'role': 'system'},\n",
       "    {'content': 'From the context \"The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is the library of the Holy See, located in Vatican City. Formally established in 1475, although it is much older, it is one of the oldest libraries in the world and contains one of the most significant collections of historical texts. It has 75,000 codices from throughout history, as well as 1.1 million printed books, which include some 8,500 incunabula. \\n\\nThe Vatican Library is a research library for history, law, philosophy, science and theology. The Vatican Library is open to anyone who can document their qualifications and research needs. Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail. \\n\\nIn March 2014, the Vatican Library began an initial four-year project of digitising its collection of manuscripts, to be made available online. \\n\\nThe Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items. \\n\\nScholars have traditionally divided the history of the library into five periods, Pre-Lateran, Lateran, Avignon, Pre-Vatican and Vatican. \\n\\nThe Pre-Lateran period, comprising the initial days of the library, dated from the earliest days of the Church. Only a handful of volumes survive from this period, though some are very significant.\" the question \"When was the Vat formally opened?\", has the correct answer as \"It was formally established in 1475\". Does the response \"The Vatican Library was formally established in 1475.\" fits the correct answer?',\n",
       "     'role': 'user'},\n",
       "    {'role': 'assistant', 'content': 'True'}]}]]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e1b1d86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'content': 'For the following query give response as True or False, nothing more.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'From the context \"The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is the library of the Holy See, located in Vatican City. Formally established in 1475, although it is much older, it is one of the oldest libraries in the world and contains one of the most significant collections of historical texts. It has 75,000 codices from throughout history, as well as 1.1 million printed books, which include some 8,500 incunabula. \\n\\nThe Vatican Library is a research library for history, law, philosophy, science and theology. The Vatican Library is open to anyone who can document their qualifications and research needs. Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail. \\n\\nIn March 2014, the Vatican Library began an initial four-year project of digitising its collection of manuscripts, to be made available online. \\n\\nThe Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items. \\n\\nScholars have traditionally divided the history of the library into five periods, Pre-Lateran, Lateran, Avignon, Pre-Vatican and Vatican. \\n\\nThe Pre-Lateran period, comprising the initial days of the library, dated from the earliest days of the Church. Only a handful of volumes survive from this period, though some are very significant.\" the question \"When was the Vat formally opened?\", has the correct answer as \"It was formally established in 1475\". Does the response \"The Vatican Library was formally established in 1475.\" fits the correct answer?',\n",
       "   'role': 'user'}],\n",
       " [{'content': 'For the following query give response as True or False, nothing more.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'From the context \"The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is the library of the Holy See, located in Vatican City. Formally established in 1475, although it is much older, it is one of the oldest libraries in the world and contains one of the most significant collections of historical texts. It has 75,000 codices from throughout history, as well as 1.1 million printed books, which include some 8,500 incunabula. \\n\\nThe Vatican Library is a research library for history, law, philosophy, science and theology. The Vatican Library is open to anyone who can document their qualifications and research needs. Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail. \\n\\nIn March 2014, the Vatican Library began an initial four-year project of digitising its collection of manuscripts, to be made available online. \\n\\nThe Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items. \\n\\nScholars have traditionally divided the history of the library into five periods, Pre-Lateran, Lateran, Avignon, Pre-Vatican and Vatican. \\n\\nThe Pre-Lateran period, comprising the initial days of the library, dated from the earliest days of the Church. Only a handful of volumes survive from this period, though some are very significant.\" the question \"When was the Vat formally opened?\", has the correct answer as \"It was formally established in 1475\". Does the response \"The Vatican Library was formally established in 1475.\" fits the correct answer?',\n",
       "   'role': 'user'}]]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[coqa_100_generations['bfloat16_verification_prompt'][0]] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329194a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
